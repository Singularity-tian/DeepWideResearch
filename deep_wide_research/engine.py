"""Native Deep Research engine orchestrating the full flow without LangChain.

This engineä¸²è”ä¸¤ä¸ªæ ¸å¿ƒç­–ç•¥:
1. Research Phase: ä½¿ç”¨ unified_research_prompt è¿›è¡Œæœç´¢å’Œä¿¡æ¯æ”¶é›†
2. Generate Phase: ä½¿ç”¨ final_report_generation_prompt ç”Ÿæˆæœ€ç»ˆæŠ¥å‘Š
"""

from __future__ import annotations

import json
from typing import Dict, List, Optional

import os
import sys

# æ”¯æŒç›´æ¥è¿è¡Œå’Œæ¨¡å—å¯¼å…¥
if __name__ == "__main__":
    from pathlib import Path
    sys.path.insert(0, str(Path(__file__).parent.parent))
    from native_deep_research.research_strategy import run_research_llm_driven
    from native_deep_research.generate_strategy import generate_report
else:
    from .research_strategy import run_research_llm_driven
    from .generate_strategy import generate_report


def today_str() -> str:
    import datetime as _dt

    now = _dt.datetime.now()
    return f"{now:%a} {now:%b} {now.day}, {now:%Y}"


async def _run_researcher(topic: str, cfg: Configuration, api_keys: Optional[dict], mcp_config: Optional[Dict[str, List[str]]] = None) -> Dict[str, str]:
    # Delegate to LLM-driven tool-calling strategy
    return await run_research_llm_driven(topic=topic, cfg=cfg, api_keys=api_keys, mcp_config=mcp_config)


# removed supervisor_tools for single-agent design


async def final_report_generation(state: dict, cfg: Configuration, api_keys: Optional[dict] = None) -> None:
    # Delegate to report strategy
    report_content = await generate_report(state=state, cfg=cfg, api_keys=api_keys)
    state["final_report"] = report_content
    state["notes"] = []
    state["messages"].append({"role": "assistant", "content": report_content})


class Configuration:
    def __init__(self):
        # Minimal config fields used in this file
        self.allow_clarification = True
        self.max_concurrent_research_units = 5
        self.max_researcher_iterations = 6
        self.max_react_tool_calls = 10
        self.research_model = os.getenv("RESEARCH_MODEL", "openai:gpt-4.1")
        self.research_model_max_tokens = int(os.getenv("RESEARCH_MODEL_MAX_TOKENS", "10000"))
        self.final_report_model = os.getenv("FINAL_REPORT_MODEL", "openai:gpt-4.1")
        self.final_report_model_max_tokens = int(os.getenv("FINAL_REPORT_MODEL_MAX_TOKENS", "10000"))
        self.mcp_prompt = None


async def run_deep_research(user_messages: List[str], cfg: Optional[Configuration] = None, api_keys: Optional[dict] = None, mcp_config: Optional[Dict[str, List[str]]] = None) -> dict:
    """å®Œæ•´çš„æ·±åº¦ç ”ç©¶æµç¨‹ï¼šResearch â†’ Generate
    
    Args:
        user_messages: ç”¨æˆ·æ¶ˆæ¯åˆ—è¡¨
        cfg: é…ç½®å¯¹è±¡
        api_keys: API å¯†é’¥
        
    Returns:
        åŒ…å«ç ”ç©¶ç»“æœå’Œæœ€ç»ˆæŠ¥å‘Šçš„ state å­—å…¸
    """
    cfg = cfg or Configuration()
    state = {
        "messages": [{"role": "user", "content": m} for m in user_messages],
        "research_brief": None,
        "notes": [],
        "final_report": "",
    }

    # æå–ç ”ç©¶ä¸»é¢˜
    last_user = next((m for m in reversed(state["messages"]) if m["role"] == "user"), {"content": ""})
    research_topic = last_user.get("content", "")

    # ============================================================
    # Phase 1: Research - ä½¿ç”¨ unified_research_prompt
    # ============================================================
    print("\nğŸ”¬ Starting Research Phase...")
    research = await _run_researcher(research_topic, cfg, api_keys, mcp_config)
    raw_notes = research.get("raw_notes", "") if research else ""
    state["notes"] = [raw_notes] if raw_notes else []
    # å°† raw_notes JSON ä¹Ÿæ³¨å…¥ messagesï¼Œä¾›ç”Ÿæˆé˜¶æ®µä½œä¸ºä¸Šä¸‹æ–‡
    if raw_notes:
        try:
            # éªŒè¯æ˜¯å¦ä¸º JSONï¼›å¦‚æœä¸æ˜¯ï¼Œä¹Ÿç…§æ ·æ”¾å…¥
            json.loads(raw_notes)
        except Exception:
            pass
        state["messages"].append({
            "role": "user",
            "content": f"<RAW_NOTES_JSON>\n{raw_notes}\n</RAW_NOTES_JSON>"
        })
    print(f"âœ… Research Phase Complete - Collected {len(state['notes'])} note(s)")

    # ============================================================
    # Phase 2: Generate - ä½¿ç”¨ final_report_generation_prompt
    # ============================================================
    print("\nğŸ“ Starting Report Generation Phase...")
    await final_report_generation(state, cfg, api_keys)
    
    # ç»Ÿä¸€å…³é—­æ‰€æœ‰ MCP clientsï¼Œé¿å…å…³é—­å‘ç”Ÿåœ¨ä¸åŒ task å¯¼è‡´çš„ cancel scope å¼‚å¸¸
    try:
        from native_deep_research.mcp_client import get_registry
    except Exception:
        try:
            from .mcp_client import get_registry
        except Exception:
            get_registry = None
    
    if get_registry is not None:
        try:
            registry = get_registry()
            if hasattr(registry, "close_all_clients"):
                await registry.close_all_clients()
        except Exception:
            pass
    print("âœ… Report Generation Complete")
    
    return state


if __name__ == "__main__":
    """åœ¨ VSCode ä¸­ç›´æ¥ç‚¹å‡» Run æŒ‰é’®å³å¯æµ‹è¯•å®Œæ•´çš„ Deep Research æµç¨‹"""
    import asyncio
    
    class TestConfig(Configuration):
        def __init__(self):
            super().__init__()
            # è‡ªå®šä¹‰æµ‹è¯•é…ç½®
            self.research_model = "openai/o4-mini"
            self.research_model_max_tokens = 16000
            self.final_report_model = "openai/o4-mini"
            self.final_report_model_max_tokens = 16000
            self.max_react_tool_calls = 5
    
    async def test():
        print("="*80)
        print("ğŸš€ Testing Deep Research Engine")
        print("="*80)
        
        # æµ‹è¯•ç”¨ä¾‹
        test_question = "DataBricks, Snowflake ä»–ä»¬åˆ†åˆ«æä¾›ä»€ä¹ˆæœåŠ¡ï¼Œä»¥åŠåŒºåˆ«æ˜¯ä»€ä¹ˆ?"
        
        # è¿è¡Œå®Œæ•´æµç¨‹
        result = await run_deep_research(
            user_messages=[test_question],
            cfg=TestConfig()
        )
        
        print("\n" + "="*80)
        print("ğŸ“Š Research Results:")
        print("="*80)
        print(f"Notes collected: {len(result['notes'])}")
        if result['notes']:
            print("\nResearch Notes:")
            print("-"*80)
            print(result['notes'][0][:500] + "..." if len(result['notes'][0]) > 500 else result['notes'][0])
        
        print("\n" + "="*80)
        print("ğŸ“„ Final Report:")
        print("="*80)
        print(result['final_report'])
        
        print("\n" + "="*80)
        print("âœ… Test Complete!")
        print("="*80)
    
    asyncio.run(test())


