"""Native Deep Research engine orchestrating the full flow without LangChain.

This engineä¸²è”ä¸¤ä¸ªæ ¸å¿ƒç­–ç•¥:
1. Research Phase: ä½¿ç”¨ unified_research_prompt è¿›è¡Œæœç´¢å’Œä¿¡æ¯æ”¶é›†
2. Generate Phase: ä½¿ç”¨ final_report_generation_prompt ç”Ÿæˆæœ€ç»ˆæŠ¥å‘Š
"""

from __future__ import annotations

import json
from typing import Dict, List, Optional

import os
import sys

# æ”¯æŒç›´æ¥è¿è¡Œå’Œæ¨¡å—å¯¼å…¥ - å°è¯•ç»å¯¹å¯¼å…¥å’Œç›¸å¯¹å¯¼å…¥
try:
    # å°è¯•ä½œä¸ºåŒ…çš„ä¸€éƒ¨åˆ†å¯¼å…¥ï¼ˆå¼€å‘ç¯å¢ƒï¼‰
    from .research_strategy import run_research_llm_driven
    from .generate_strategy import generate_report
except ImportError:
    # å°è¯•ç»å¯¹å¯¼å…¥ï¼ˆç›´æ¥è¿è¡Œæˆ–éƒ¨ç½²ç¯å¢ƒï¼‰
    try:
        from deep_wide_research.research_strategy import run_research_llm_driven
        from deep_wide_research.generate_strategy import generate_report
    except ImportError:
        # ä½œä¸ºç‹¬ç«‹æ¨¡å—å¯¼å…¥ï¼ˆRailway éƒ¨ç½²ç¯å¢ƒï¼‰
        from research_strategy import run_research_llm_driven
        from generate_strategy import generate_report


def today_str() -> str:
    import datetime as _dt

    now = _dt.datetime.now()
    return f"{now:%a} {now:%b} {now.day}, {now:%Y}"


async def _run_researcher(topic: str, cfg: Configuration, api_keys: Optional[dict], mcp_config: Optional[Dict[str, List[str]]] = None, deep_param: float = 0.5, wide_param: float = 0.5, status_callback=None) -> Dict[str, str]:
    # Delegate to LLM-driven tool-calling strategy
    return await run_research_llm_driven(topic=topic, cfg=cfg, api_keys=api_keys, mcp_config=mcp_config, deep_param=deep_param, wide_param=wide_param, status_callback=status_callback)



# removed supervisor_tools for single-agent design


async def final_report_generation(state: dict, cfg: Configuration, api_keys: Optional[dict] = None) -> None:
    # Delegate to report strategy
    report_content = await generate_report(state=state, cfg=cfg, api_keys=api_keys)
    state["final_report"] = report_content
    state["notes"] = []
    state["messages"].append({"role": "assistant", "content": report_content})


class Configuration:
    def __init__(self):
        # Minimal config fields used in this file
        self.allow_clarification = True
        self.max_concurrent_research_units = 5
        self.max_researcher_iterations = 6
        self.max_react_tool_calls = 10
        self.research_model = os.getenv("RESEARCH_MODEL", "openai:gpt-4.1")
        self.research_model_max_tokens = int(os.getenv("RESEARCH_MODEL_MAX_TOKENS", "10000"))
        self.final_report_model = os.getenv("FINAL_REPORT_MODEL", "openai:gpt-4.1")
        self.final_report_model_max_tokens = int(os.getenv("FINAL_REPORT_MODEL_MAX_TOKENS", "10000"))
        self.mcp_prompt = None


async def run_deep_research_stream(user_messages: List[str], cfg: Optional[Configuration] = None, api_keys: Optional[dict] = None, mcp_config: Optional[Dict[str, List[str]]] = None, deep_param: float = 0.5, wide_param: float = 0.5):
    """æµå¼ç‰ˆæœ¬çš„æ·±åº¦ç ”ç©¶æµç¨‹ï¼šResearch â†’ Generate
    
    Yields:
        çŠ¶æ€æ›´æ–°å­—å…¸ï¼ŒåŒ…å« action å’Œ message å­—æ®µ
    """
    cfg = cfg or Configuration()
    state = {
        "messages": [{"role": "user", "content": m} for m in user_messages],
        "research_brief": None,
        "notes": [],
        "final_report": "",
    }

    # æå–ç ”ç©¶ä¸»é¢˜
    last_user = next((m for m in reversed(state["messages"]) if m["role"] == "user"), {"content": ""})
    research_topic = last_user.get("content", "")

    # ============================================================
    # Phase 1: Research - ä½¿ç”¨ unified_research_prompt
    # ============================================================
    yield {"action": "thinking", "message": "thinking..."}
    
    # è®©ç”¨æˆ·çœ‹åˆ°thinkingçŠ¶æ€
    import asyncio
    await asyncio.sleep(1.5)
    
    # åˆ›å»ºä¸€ä¸ªé˜Ÿåˆ—æ¥æ¥æ”¶çŠ¶æ€æ›´æ–°
    from asyncio import Queue
    status_queue = Queue()
    
    # åˆ›å»ºçŠ¶æ€å›è°ƒå‡½æ•°
    async def status_callback(message: str):
        await status_queue.put(message)
    
    # å¯åŠ¨ç ”ç©¶ä»»åŠ¡
    research_task = asyncio.create_task(_run_researcher(research_topic, cfg, api_keys, mcp_config, deep_param, wide_param, status_callback))
    
    # ä»é˜Ÿåˆ—ä¸­è¯»å–å¹¶yieldçŠ¶æ€æ›´æ–°
    while not research_task.done():
        try:
            # å°è¯•è·å–çŠ¶æ€æ›´æ–°ï¼ˆçŸ­è¶…æ—¶ï¼‰
            message = await asyncio.wait_for(status_queue.get(), timeout=0.1)
            yield {"action": "using_tools", "message": message}
        except asyncio.TimeoutError:
            # æ²¡æœ‰æ¶ˆæ¯ï¼Œç»§ç»­ç­‰å¾…
            continue
    
    # ç ”ç©¶å®Œæˆåï¼Œå¤„ç†é˜Ÿåˆ—ä¸­çš„å‰©ä½™æ¶ˆæ¯
    while not status_queue.empty():
        try:
            message = status_queue.get_nowait()
            yield {"action": "using_tools", "message": message}
        except asyncio.QueueEmpty:
            break
    
    # è·å–ç ”ç©¶ç»“æœ
    research = await research_task
    raw_notes = research.get("raw_notes", "") if research else ""
    state["notes"] = [raw_notes] if raw_notes else []
    
    if raw_notes:
        try:
            json.loads(raw_notes)
        except Exception:
            pass
        state["messages"].append({
            "role": "user",
            "content": f"<RAW_NOTES_JSON>\n{raw_notes}\n</RAW_NOTES_JSON>"
        })

    # ============================================================
    # Phase 2: Generate - ä½¿ç”¨ final_report_generation_prompt
    # ============================================================
    yield {"action": "generating", "message": "research finished, generating..."}
    
    await final_report_generation(state, cfg, api_keys)
    
    # ç»Ÿä¸€å…³é—­æ‰€æœ‰ MCP clients
    try:
        from deep_wide_research.mcp_client import get_registry
    except Exception:
        try:
            from .mcp_client import get_registry
        except Exception:
            get_registry = None
    
    if get_registry is not None:
        try:
            registry = get_registry()
            if hasattr(registry, "close_all_clients"):
                await registry.close_all_clients()
        except Exception:
            pass
    
    # å‘é€æœ€ç»ˆç»“æœ
    yield {"action": "complete", "message": state["final_report"], "final_report": state["final_report"]}


async def run_deep_research(user_messages: List[str], cfg: Optional[Configuration] = None, api_keys: Optional[dict] = None, mcp_config: Optional[Dict[str, List[str]]] = None, deep_param: float = 0.5, wide_param: float = 0.5) -> dict:
    """å®Œæ•´çš„æ·±åº¦ç ”ç©¶æµç¨‹ï¼šResearch â†’ Generate
    
    Args:
        user_messages: ç”¨æˆ·æ¶ˆæ¯åˆ—è¡¨
        cfg: é…ç½®å¯¹è±¡
        api_keys: API å¯†é’¥
        
    Returns:
        åŒ…å«ç ”ç©¶ç»“æœå’Œæœ€ç»ˆæŠ¥å‘Šçš„ state å­—å…¸
    """
    cfg = cfg or Configuration()
    state = {
        "messages": [{"role": "user", "content": m} for m in user_messages],
        "research_brief": None,
        "notes": [],
        "final_report": "",
    }

    # æå–ç ”ç©¶ä¸»é¢˜
    last_user = next((m for m in reversed(state["messages"]) if m["role"] == "user"), {"content": ""})
    research_topic = last_user.get("content", "")

    # ============================================================
    # Phase 1: Research - ä½¿ç”¨ unified_research_prompt
    # ============================================================
    research = await _run_researcher(research_topic, cfg, api_keys, mcp_config, deep_param, wide_param)
    raw_notes = research.get("raw_notes", "") if research else ""
    state["notes"] = [raw_notes] if raw_notes else []
    # å°† raw_notes JSON ä¹Ÿæ³¨å…¥ messagesï¼Œä¾›ç”Ÿæˆé˜¶æ®µä½œä¸ºä¸Šä¸‹æ–‡
    if raw_notes:
        try:
            # éªŒè¯æ˜¯å¦ä¸º JSONï¼›å¦‚æœä¸æ˜¯ï¼Œä¹Ÿç…§æ ·æ”¾å…¥
            json.loads(raw_notes)
        except Exception:
            pass
        state["messages"].append({
            "role": "user",
            "content": f"<RAW_NOTES_JSON>\n{raw_notes}\n</RAW_NOTES_JSON>"
        })
    # ============================================================
    # Phase 2: Generate - ä½¿ç”¨ final_report_generation_prompt
    # ============================================================
    await final_report_generation(state, cfg, api_keys)
    
    # ç»Ÿä¸€å…³é—­æ‰€æœ‰ MCP clientsï¼Œé¿å…å…³é—­å‘ç”Ÿåœ¨ä¸åŒ task å¯¼è‡´çš„ cancel scope å¼‚å¸¸
    try:
        from deep_wide_research.mcp_client import get_registry
    except Exception:
        try:
            from .mcp_client import get_registry
        except Exception:
            get_registry = None
    
    if get_registry is not None:
        try:
            registry = get_registry()
            if hasattr(registry, "close_all_clients"):
                await registry.close_all_clients()
        except Exception:
            pass
    
    return state


if __name__ == "__main__":
    """åœ¨ VSCode ä¸­ç›´æ¥ç‚¹å‡» Run æŒ‰é’®å³å¯æµ‹è¯•å®Œæ•´çš„ Deep Research æµç¨‹"""
    import asyncio
    
    class TestConfig(Configuration):
        def __init__(self):
            super().__init__()
            # è‡ªå®šä¹‰æµ‹è¯•é…ç½®
            self.research_model = "openai/o4-mini"
            self.research_model_max_tokens = 16000
            self.final_report_model = "openai/o4-mini"
            self.final_report_model_max_tokens = 16000
            self.max_react_tool_calls = 5
    
    async def test():
        print("="*80)
        print("ğŸš€ Testing Deep Research Engine")
        print("="*80)
        
        # æµ‹è¯•ç”¨ä¾‹
        test_question = "DataBricks, Snowflake ä»–ä»¬åˆ†åˆ«æä¾›ä»€ä¹ˆæœåŠ¡ï¼Œä»¥åŠåŒºåˆ«æ˜¯ä»€ä¹ˆ?"
        
        # è¿è¡Œå®Œæ•´æµç¨‹
        result = await run_deep_research(
            user_messages=[test_question],
            cfg=TestConfig()
        )
        
        print("\n" + "="*80)
        print("ğŸ“Š Research Results:")
        print("="*80)
        print(f"Notes collected: {len(result['notes'])}")
        if result['notes']:
            print("\nResearch Notes:")
            print("-"*80)
            print(result['notes'][0][:500] + "..." if len(result['notes'][0]) > 500 else result['notes'][0])
        
        print("\n" + "="*80)
        print("ğŸ“„ Final Report:")
        print("="*80)
        print(result['final_report'])
        
        print("\n" + "="*80)
        print("Test Complete!")
        print("="*80)
    
    asyncio.run(test())


