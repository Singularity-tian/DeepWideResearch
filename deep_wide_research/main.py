"""FastAPI server for Deep Research Engine.

æä¾› HTTP API æ¥å£æ¥è°ƒç”¨æ·±åº¦ç ”ç©¶å¼•æ“ã€‚
"""

import sys
from pathlib import Path

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ° Python è·¯å¾„ï¼Œä»¥ä¾¿æ­£ç¡®å¯¼å…¥æ¨¡å—
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

# åŒæ—¶æ·»åŠ å½“å‰ç›®å½•åˆ°è·¯å¾„ï¼ˆç”¨äº Railway éƒ¨ç½²ï¼‰
current_dir = Path(__file__).parent
sys.path.insert(0, str(current_dir))

from fastapi import FastAPI, HTTPException, Response
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import StreamingResponse
from pydantic import BaseModel
from typing import List, Optional, Dict, Any
import asyncio
import json

# å°è¯•ä¸¤ç§å¯¼å…¥æ–¹å¼ï¼šå¼€å‘ç¯å¢ƒå’Œéƒ¨ç½²ç¯å¢ƒ
try:
    from deep_wide_research.engine import run_deep_research, run_deep_research_stream, Configuration
except ImportError:
    from engine import run_deep_research, run_deep_research_stream, Configuration

app = FastAPI(title="PuppyResearch API", version="1.0.0")

# é…ç½® CORSï¼Œå…è®¸å‰ç«¯è®¿é—®
import os

# æ£€æµ‹æ˜¯å¦ä¸ºç”Ÿäº§ç¯å¢ƒ
is_production = bool(os.getenv("RAILWAY_ENVIRONMENT") or os.getenv("RENDER") or os.getenv("VERCEL"))

if is_production:
    # ç”Ÿäº§ç¯å¢ƒï¼šå¿…é¡»ä½¿ç”¨ç¯å¢ƒå˜é‡é…ç½®
    allowed_origins_env = os.getenv("ALLOWED_ORIGINS", "")
    if allowed_origins_env:
        allowed_origins = [origin.strip() for origin in allowed_origins_env.split(",") if origin.strip()]
        allow_all_origins = False
    else:
        raise ValueError(
            "âš ï¸  Production environment detected but ALLOWED_ORIGINS is not set!\n"
            "Please set the ALLOWED_ORIGINS environment variable with your frontend URL(s).\n"
            "Example: ALLOWED_ORIGINS=https://your-frontend.vercel.app,https://www.your-domain.com"
        )
else:
    # æœ¬åœ°å¼€å‘ï¼šæ°¸è¿œå…è®¸æ‰€æœ‰æ¥æºï¼ˆæ–¹ä¾¿å¼€å‘ï¼‰
    allowed_origins = ["*"]
    allow_all_origins = True
    print("ğŸ’¡ Tip: Running in development mode with CORS set to allow all origins (*)")

# æ‰“å° CORS é…ç½®ï¼ˆç”¨äºè°ƒè¯•ï¼‰
print("="*80)
print("ğŸ”§ CORS Configuration:")
print(f"   Environment: {'ğŸŒ Production' if is_production else 'ğŸ’» Development (Local)'}")
print(f"   Allowed Origins: {allowed_origins}")
print(f"   Allow All Origins: {'âœ… Yes (*)' if allow_all_origins else 'âŒ No (Restricted)'}")
print(f"   Allow Credentials: {'âœ… Yes' if not allow_all_origins else 'âŒ No (incompatible with *)'}")
print("="*80)

app.add_middleware(
    CORSMiddleware,
    allow_origins=allowed_origins,
    allow_credentials=not allow_all_origins,  # ä½¿ç”¨ * æ—¶ä¸èƒ½å¯ç”¨ credentials
    allow_methods=["*"],
    allow_headers=["*"],
    expose_headers=["*"],
    max_age=3600,
)


class Message(BaseModel):
    """æ¶ˆæ¯æ¨¡å‹ - æ ‡å‡†çš„ OpenAI æ ¼å¼"""
    role: str  # "user", "assistant", or "system"
    content: str


class DeepWideParams(BaseModel):
    """æ·±åº¦å’Œå¹¿åº¦å‚æ•°æ¨¡å‹"""
    deep: float = 0.5  # æ·±åº¦å‚æ•° (0-1)ï¼Œæ§åˆ¶ç ”ç©¶çš„æ·±åº¦
    wide: float = 0.5  # å¹¿åº¦å‚æ•° (0-1)ï¼Œæ§åˆ¶ç ”ç©¶çš„å¹¿åº¦


class ResearchMessage(BaseModel):
    """ç ”ç©¶æ¶ˆæ¯æ¨¡å‹ - åŒ…å«æŸ¥è¯¢å’Œå‚æ•°"""
    query: str  # ç”¨æˆ·çš„æŸ¥è¯¢æ–‡æœ¬
    deepwide: DeepWideParams = DeepWideParams()  # æ·±åº¦å¹¿åº¦å‚æ•°å¯¹è±¡
    mcp: Dict[str, List[str]] = {}  # MCPé…ç½®ï¼š{æœåŠ¡å: [å·¥å…·åˆ—è¡¨]}


class ResearchRequest(BaseModel):
    """ç ”ç©¶è¯·æ±‚æ¨¡å‹"""
    message: ResearchMessage  # ç°åœ¨æ˜¯ä¸€ä¸ªå¯¹è±¡è€Œä¸æ˜¯å­—ç¬¦ä¸²
    history: Optional[List[Message]] = None


class ResearchResponse(BaseModel):
    """ç ”ç©¶å“åº”æ¨¡å‹"""
    response: str
    notes: List[str] = []
    success: bool = True


@app.get("/")
async def root():
    """API æ ¹è·¯å¾„"""
    return {
        "name": "PuppyResearch API",
        "version": "1.0.0",
        "status": "running"
    }


@app.get("/health")
async def health_check():
    """å¥åº·æ£€æŸ¥ç«¯ç‚¹"""
    return {"status": "healthy"}


@app.get("/api/mcp/status")
async def mcp_status():
    """æ£€æŸ¥ MCP ç¯å¢ƒå˜é‡çŠ¶æ€ï¼ˆè°ƒè¯•ç”¨ï¼‰"""
    import os
    return {
        "tavily_api_key_set": bool(os.getenv("TAVILY_API_KEY")),
        "exa_api_key_set": bool(os.getenv("EXA_API_KEY")),
        "openai_api_key_set": bool(os.getenv("OPENAI_API_KEY"))
    }


async def research_stream_generator(request: ResearchRequest):
    """ç”Ÿæˆç ”ç©¶æµå¼å“åº”"""
    try:
        # æ„å»ºæ¶ˆæ¯å†å²
        history_messages = request.history or []
        user_messages = [msg.content for msg in history_messages if msg.role == "user"]
        user_messages.append(request.message.query)
        
        # åˆ›å»ºé…ç½®
        cfg = Configuration()
        
        print(f"\nğŸ” Received research request: {request.message.query}")
        print(f"ğŸ“Š Deep: {request.message.deepwide.deep}, Wide: {request.message.deepwide.wide}")
        
        # æ‰§è¡Œç ”ç©¶å¹¶è·å–æµå¼æ›´æ–°
        async for update in run_deep_research_stream(
            user_messages=user_messages,
            cfg=cfg,
            api_keys=None,
            mcp_config=request.message.mcp,
            deep_param=request.message.deepwide.deep,
            wide_param=request.message.deepwide.wide
        ):
            yield f"data: {json.dumps(update)}\n\n"
            
    except Exception as e:
        error_msg = {'action': 'error', 'message': f'Research failed: {str(e)}'}
        yield f"data: {json.dumps(error_msg)}\n\n"


@app.post("/api/research")
async def research(request: ResearchRequest):
    """æ‰§è¡Œæ·±åº¦ç ”ç©¶ - æµå¼å“åº”"""
    return StreamingResponse(
        research_stream_generator(request),
        media_type="text/event-stream",
        headers={
            "Cache-Control": "no-cache",
            "Connection": "keep-alive",
            "X-Accel-Buffering": "no",
        }
    )


class MCPTestRequest(BaseModel):
    """MCP æµ‹è¯•è¯·æ±‚æ¨¡å‹"""
    services: List[str]  # è¦æµ‹è¯•çš„æœåŠ¡åç§°åˆ—è¡¨ï¼Œå¦‚ ["tavily", "exa"]


class MCPToolInfo(BaseModel):
    """MCP å·¥å…·ä¿¡æ¯"""
    name: str
    description: str = ""


class MCPServiceStatus(BaseModel):
    """MCP æœåŠ¡çŠ¶æ€"""
    name: str
    available: bool
    tools: List[MCPToolInfo] = []
    error: Optional[str] = None


class MCPTestResponse(BaseModel):
    """MCP æµ‹è¯•å“åº”æ¨¡å‹"""
    services: List[MCPServiceStatus]


@app.post("/api/mcp/test", response_model=MCPTestResponse)
async def test_mcp_services(request: MCPTestRequest):
    """æµ‹è¯• MCP æœåŠ¡è¿æ¥çŠ¶æ€
    
    æ£€æŸ¥ MCP æœåŠ¡æ˜¯å¦å¯ç”¨ï¼š
    - æœ¬åœ°ç¯å¢ƒï¼šæ£€æŸ¥ API key æ˜¯å¦è®¾ç½®
    - äº‘ç«¯ç¯å¢ƒï¼ˆHTTP MCPï¼‰ï¼šå®é™…æµ‹è¯• HTTP è¿æ¥
    """
    import os
    import httpx
    
    is_production = bool(os.getenv("RAILWAY_ENVIRONMENT") or os.getenv("RENDER") or os.getenv("VERCEL"))
    
    # MCP æœåŠ¡çš„é…ç½®æ˜ å°„
    mcp_config = {
        "tavily": {
            "api_key_env": "TAVILY_API_KEY",
            "http_url_template": "https://mcp.tavily.com/mcp/?tavilyApiKey={api_key}",
            "default_tools": [
                {"name": "tavily-search", "description": "Search the web using Tavily"},
                {"name": "tavily-extract", "description": "Extract content from URLs"}
            ]
        },
        "exa": {
            "api_key_env": "EXA_API_KEY",
            "http_url_template": "https://mcp.exa.ai/mcp?exaApiKey={api_key}",
            "default_tools": [
                {"name": "web_search_exa", "description": "AI-powered web search using Exa"}
            ]
        }
    }
    
    results = []
    for service_name in request.services:
        service_name_lower = service_name.lower()
        
        # æ£€æŸ¥æœåŠ¡æ˜¯å¦åœ¨é…ç½®ä¸­
        if service_name_lower not in mcp_config:
            results.append(MCPServiceStatus(
                name=service_name,
                available=False,
                error=f"Unknown service '{service_name}'. Supported: Tavily, Exa"
            ))
            continue
        
        config = mcp_config[service_name_lower]
        api_key = os.getenv(config["api_key_env"])
        
        if not api_key:
            # API key æœªè®¾ç½®
            results.append(MCPServiceStatus(
                name=service_name,
                available=False,
                error=f"API key not set. Please set {config['api_key_env']} environment variable."
            ))
            continue
        
        # å¦‚æœæ˜¯ç”Ÿäº§ç¯å¢ƒï¼Œå°è¯•å®é™…æµ‹è¯• HTTP è¿æ¥
        if is_production:
            try:
                http_url = config["http_url_template"].format(api_key=api_key)
                
                # å°è¯•è¿æ¥ MCP HTTP æœåŠ¡ï¼ˆä½¿ç”¨ SSE è¿æ¥æµ‹è¯•ï¼‰
                async with httpx.AsyncClient(timeout=10.0) as client:
                    # å‘é€ SSE è¿æ¥è¯·æ±‚
                    response = await client.get(
                        http_url,
                        headers={"Accept": "text/event-stream"}
                    )
                    
                    if response.status_code == 200:
                        # è¿æ¥æˆåŠŸï¼Œä½¿ç”¨é»˜è®¤å·¥å…·åˆ—è¡¨
                        # TODO: å¯ä»¥è§£æ SSE å“åº”è·å–å®é™…å·¥å…·åˆ—è¡¨
                        tool_infos = [
                            MCPToolInfo(name=tool["name"], description=tool["description"])
                            for tool in config["default_tools"]
                        ]
                        
                        results.append(MCPServiceStatus(
                            name=service_name,
                            available=True,
                            tools=tool_infos
                        ))
                    else:
                        results.append(MCPServiceStatus(
                            name=service_name,
                            available=False,
                            error=f"HTTP {response.status_code}: Cannot connect to MCP service"
                        ))
                        
            except httpx.TimeoutException:
                results.append(MCPServiceStatus(
                    name=service_name,
                    available=False,
                    error="Connection timeout: MCP service is not responding"
                ))
            except httpx.ConnectError:
                results.append(MCPServiceStatus(
                    name=service_name,
                    available=False,
                    error="Connection refused: Cannot reach MCP service"
                ))
            except Exception as e:
                results.append(MCPServiceStatus(
                    name=service_name,
                    available=False,
                    error=f"Connection failed: {str(e)}"
                ))
        else:
            # æœ¬åœ°ç¯å¢ƒï¼šåªæ£€æŸ¥ API keyï¼Œè¿”å›é»˜è®¤å·¥å…·åˆ—è¡¨
            tool_infos = [
                MCPToolInfo(name=tool["name"], description=tool["description"])
                for tool in config["default_tools"]
            ]
            
            results.append(MCPServiceStatus(
                name=service_name,
                available=True,
                tools=tool_infos
            ))
    
    return MCPTestResponse(services=results)


if __name__ == "__main__":
    import uvicorn
    
    print("="*80)
    print("ğŸš€ Starting PuppyResearch API Server")
    print("="*80)
    print("ğŸ“¡ Server will be available at: http://localhost:8000")
    print("ğŸ“š API docs at: http://localhost:8000/docs")
    print("="*80)
    
    uvicorn.run(
        app,
        host="0.0.0.0",
        port=8000,
        log_level="info"
    )

